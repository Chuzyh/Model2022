\documentclass{ctexart}
\usepackage{xcolor}
\usepackage{setspace}
\usepackage{tikz}
\usepackage{ctex}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{graphicx} 
\usepackage{subfigure}
\usepackage{float}
\usepackage{algorithm}  
\usepackage{algorithmicx}  
\usepackage{algpseudocode} 
\usepackage{url}
\usepackage{amsthm, amssymb, appendix, bm, graphicx, hyperref, mathrsfs}

\usepackage{listings}
\usepackage{float}
\pagestyle{plain}

\usetikzlibrary{datavisualization}
\usetikzlibrary{arrows,shapes,chains}
\usepackage{listings}
\lstset{language=C++}
\lstset{breaklines}
\lstset{extendedchars=false}
\lstset{numbers=left}
\geometry{a4paper,left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\CTEXsetup[format={\Large\bfseries\centering}]{section}
\tikzstyle{startstop} = [rectangle,rounded corners, minimum width=3cm,minimum height=1cm,text centered, text width=6cm,draw=black]
\tikzstyle{io} = [trapezium, trapezium left angle = 70,trapezium right angle=110,minimum width=5cm,minimum height=1cm,text centered,draw=black,fill=white]
\tikzstyle{process} = [rectangle,minimum width=3cm,minimum height=1cm,text centered,text width =3cm,text width=6cm,draw=black]
\tikzstyle{decision} = [diamond,minimum width=3cm,minimum height=1cm,text centered,text width=6cm,aspect=2,draw=black,thin]
\tikzstyle{arrow} = [thick,->,>=stealth]
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm  
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm  
\newcommand{\subsubsubsection}[1]{\paragraph{#1}\mbox{}\\}
\setcounter{secnumdepth}{4} % how many sectioning levels to assign numbers to
\setcounter{tocdepth}{4} % how many sectioning levels to show in ToC


\begin{document}
    \begin{spacing}{2.0}
        \begin{center}
            {\LARGE\textbf{基于xx的xx的研究}}\\
            {\Large\textbf{摘要}}\\
        \end{center}
    \end{spacing}

    本文研究的是xx，通过建立xx和xx模型，求解得到xxx，获得xx。（问题及求解概括）
    
    首先采用xx法对已知数据进行xx补全，为模型建立提供数据基础。（数据预处理步骤，可加原因）
    
    \textbf{针对问题一：}\quad 基于附件x中的数据/基于前两问的求解，构建\textbf{xx模型}，【模型作用】，然后
    
    \textbf{针对问题二}\quad 

    \textbf{针对问题三}\quad 
 
    \textbf{针对问题四}\quad 
    
    
    \quad

    \textbf{关键词: \quad 时序数据特征提取\quad 最小二乘法\quad 决策树 }

    \newpage
    \section{问题重述}
    某云服务厂商为适应市场发展方向，由大力扩张转为优质服务，尽可能降低用户的流失率，需根据附件1和3中各项指标对用户的监控数据建立一个判断用户是否流失的模型，同时预测附件4中用户的流失与否及流失时间。云服务商共提供156个监控指标，即用户对云服务产品（计算、存储、网络）的使用情况。

    问题一：本题要求从156个监控指标中筛选出能判定用户流失性的重要指标。附件中给出了156个监控指标对250个用户在不同时间点的监测，为一系列时序数据。由于数据量过大且许多数据并不完整，故需对数据进行预处理，筛除无效数据。

    问题二：附件1中为流失用户的各项数据，附件3中为正常用户的相关数据，题目要求根据这两类不同用户的资源利用情况，建模刻画用户画像，给出能进行流失风险等级划分的量化表达式。

    对于第3-4问，需预测附件4中的用户是否流失且在哪个时间范围内流失。

    问题三：问题三要求基于问题一给出的重要监控指标构建用户流失预测模型，说明流失用户的监控指标长期变化趋势特征。并计算该模型的精确率、召回率及F1-score来评价准确性及其对相关因素的依赖性。最终预测附件4中的用户流失性。

    问题四：要求基于问题二构建的模型，预测用户最终流失点所在范围。

    \section{问题分析}
    监控指标分为计算、存储和网络三大类，计算类监控指标包含资源使用率等监控指标；存储类监控指标包含磁盘使用率等监控指标；网络类监控指标包含平均出入网流量等监控指标。根据经验，我们所选取的重要指标应该大致均匀分布在这三类中。由于附件中所给的均为时序数据，故需先选取合适的时序特征来进行分析。

    \subsection{问题一：}问题一要求在已知为流失用户的情况下，寻找监控指标数据的共同特征，从而在156个指标中找出有重要贡献的数个指标。首先，对各用户在各个指标下随时间变化的数据进行可视化，以此来分析流失原因，找出与之相关的时序特征。得到可用的时序特征后，可以利用归一化后的样本方差来衡量这些指标在不同流失用户中的共同特性，找出其中最为重要的指标。

        \subsection{问题二：} 题中要求对附件1中250个用户，附件3中182名正常用户的行为特征进行差异化分析，得出能判断用户风险等级的量化方式。为将问题抽象化，我们可以借用问题一中所得到的重要指标构建一个带有这些变量的表达式。

        为更好地区分流失用户与正常用户，我们运用最小二乘法得到一个较优的表达式，使其能够在代入流失用户的数据时尽可能趋向于0，代入正常用户的数据时尽可能趋向于1。

        最终根据代入表达式后的评分来划分相应的风险等级。

	    	
        \subsection{问题三：} 题目要求我们利用附近1和3中的数据，得到用户流失预测模型，既对于一个给定的用户数据，我们的模型需要判断他是否为流失用户。针对此二分类问题，我们使用CART算法构造决策树来作为预测模型。为了让得到的模型对更具有广泛的适用性，我们使用问题一中得到的重要监控指标计算出的特征值作为训练数据，同时为了每个训练数据点完整，我们删去了监控指标较少的用户，并将剩下的用户中空缺的特征值用平均数填补，打上01标记后作为训练数据输入给CART算法。得到模型后，我们将附件1中的所有用户数据输入，作为一个测试集；再讲附件1和3中的全部384个用户数据作为另一个测试集计算FL-score。
        

        \subsection{问题四：} 由于之前的问题构建的模型只能返回一个值表示用户的流失风险，我们在预测附近4中的用户的流失时间时，将每个用户的数据按照时间每隔一个月切片，将一年内的监控数据分解成前1-12月的十二份数据，分别计算模型输出，得到每个用户是否流失的预测数据序列，将最后一个没有流失的月份的后一个月作为用户流失的预测时间。


    \section{模型假设}
    （1）附件所给数据均准确无误；

    （2）监控指标间没有较大的包含性，在问题二的解决过程中可以用一个线性表达式来构造损失函数；

    （3）问题三、四中假设用户流失与否与所给的监控数据之间满足某种分布，且对用户不同时间点的监控采样是独立同分布的。

    \section{符号说明}
    \begin{center}
        \begin{tabular}{|c|c|}
            \hline
            符号&说明\\
            \hline
            $X_{i,j}$&监控指标特征i监测第j个用户所获取的数据\\
            \hline
            $X1_{i,j}$&归一化处理监控指标特征i中第j个用户的监测值后的数据\\
            \hline
            $N_i$&监控指标特征i监测到的用户总数\\
            \hline
            $\overline{X1_{i}}$&监控指标特征i归一化后该组数据的均值\\
            \hline
            $MseX_i$&监控指标特征i归一化后该组数据的样本方差\\
            \hline
            $K_{i,j}$&第i个监控指标监测第j个用户采集到的所有数据点的个数\\
            \hline
            $X_{i,j,t_k}$&监控指标特征i监测第j个用户在第k个时间采集点的数据\\
            \hline
            $n(\overline{X_{i,j}})$&第i个监控指标监测第j个用户所得数据中大于均值的个数\\
            \hline
            $f$&流失风险定量数值\\
            \hline
            $p_k$&样本点属于第k个类的概率\\
            \hline
            $Gini(D,A)$&经A=a分割后集合D的不确定性\\
            \hline
            $|T|$&树的复杂度\\
            \hline
            $\alpha$&权重系数\\

            \hline
        \end{tabular}\\
    \end{center}

    \section{数据预处理}

        本题附件1提供了250个流失用户近一年内156个监控指标的相关数据。由于数据量较大，需要对所给的数据进行一定的预处理，以防止其中存在错误的数据，使得计算时对结果造成影响导致出现误差。

        借助c++对附件1中数据进行整理，得到每个监控指标监测到的所有用户数量。如下表所示：

        \begin{center}

            \textbf{表1：对附件1数据的统计性分析表}
            \\ \hspace*{\fill} \\

            \begin{tabular}{|c|c|c|}
                \hline
                \textbf{监控指标}&\textbf{编号}&\textbf{用户数量}\\
                \hline
                1,1,1&1&241\\
                1,1,2&2&241\\
                1,1,3&3&241\\
                1,1,4&4&241\\
                2,3,1&5&12\\
                2,3,2&6&12\\
                ...&...&...\\
    
                \hline
            \end{tabular}\\
        \end{center}

        由上表可知，14.8\%的监控指标监测到的用户数量在240以上，25.9\%的监控指标监测到的用户数量在100-160之间，59.3\%的监控指标监测到的用户数量在30以内，明显可见不同的监控指标间存在明显的监测断层（具体表格数据见附录中的<指标值统计.txt>）。其中，用户量过少的监控指标对流失用户这一特征的体现并不显著。

        基于假设1，所有用户近一年内所有监控指标数据均无误。结合如上表格，认定监测用户数小于30次的监控指标为极低质量监控指标。因此为防止其作为极值影响后续计算结果，将(2,3,1)，(2,3,2)等80个极低质量监控指标从数据集中剔除，附录中给出了剔除的80个监控指标的详细数据。

        至此完成数据的整理与剔除，后文的建模与求解均建立在此数据预处理的基础上进行。

    \section{问题一的模型建立与求解}

    本问要求基于250个用户不同监控指标的数据对流失用户的特征进行量化分析，建立筛选指标模型，并在此基础上给出能反映流失用户特征的数个重要指标。在本问题中，由于绝大部分监控指标的数据均有缺失，故本文将从所给的历史数据中选取能覆盖大部分用户的子集来衡量有关指标与用户流失特征的相关性，给出具有较强相关性的5个指标。同时为了压缩指标数量，本文用主成分分析法得出最终的重要指标。

    \subsection{数据分析}

    观察附录1中的数据可以发现，每个监控指标监测的是用户不同时间点的数值，为更好地进行特征提取，需要选取合适的数字特征来描述它的整体状态，从而将数个时间点上的数据浓缩至几个不同的数据。将这些新的分类标号，组成原监控指标的第四维，再对细化后的监控指标进行相关性分析。


    \subsubsection{数字特征的构想}

    每一个监控指标对每一个用户均为一段时间上的监测，将时间作为X轴，监控指标数值作为Y轴，便可以画出每个用户在每个监控指标的监测下数值随时间的变化趋势。通过对图像进行分析，找出有典型性的几幅图像，对流失原因进行猜测并用合适的数字特征来描述。

    a.最大值（编号1）

    \begin{center}
        \begin{figure}[H]
            \begin{center}
                \includegraphics[width=0.50\linewidth]{pic/1.jpg}
            \end{center}
        \end{figure}
        图1：典型折线图1
    \end{center}

    从图中可以看出，流失用户的这类特征是数值达到一个峰值后迅速下降，最后趋于0。于是猜想，这类用户的流失原因可能与该段时间内数值的最大值有关。故选取最大值这一数字特征。

    \[
        max{X_{i,j,t}}
    \]

    其中，$X_{i,j,t}$表示第j个用户在第i个监控指标下一段时间内的最大值，t表示该指标所能监测到的时间范围。

    b.平均绝对差分（编号2）

    \begin{center}
        \begin{figure}[H]
            \begin{center}
                \includegraphics[width=1.00\linewidth]{pic/2.jpg}
            \end{center}
        \end{figure}
        图2：典型折线图2
    \end{center}

    从两张图中可以看出，这些用户的某个监控指标都经过了许多的波动。用户不稳定的表现一定程度上反映了其对云服务的依赖性较低，最终导致了流失，故猜想波动性能反映流失特征。本文用标记时间点之间的数据差分累计值来表示波动性，但不同用户被监测的时间点的个数并不相同，故选取平均值来表示。

    \[
        \frac{1}{K_{i,j}}\sum_{k=1}^{K_{i,j}-1}{|X_{i,j,t_{k+1}}-X_{i,j,t_k}|}
    \]

    其中，$K_{i,j}$是指第i个监控指标监测第j个用户采集到的所有数据点的个数，$X_{i,j,t_k}$是指监控指标特征i监测第j个用户在第k个时间采集点的数据。

    c.大于均值数据点比例（编号3）

    \begin{center}
        \begin{figure}[H]
            \begin{center}
                \includegraphics[width=0.50\linewidth]{pic/3.jpg}
            \end{center}
        \end{figure}
        图3：典型折线图3
    \end{center}

    由上图可以看出，该用户在这一监控指标下数据整体偏低，除了部分高峰值。为排掉这部分高峰值的影响，本文选取大于均值数据点比例这一特征来说明用户的整体情况，比例越小，说明用户只是偶尔高频使用云服务，结果依然会流失。

    \[
        \frac{n(\overline{X_{i,j}})}{K(X_{i,j})}
    \]

    其中，$n(\overline{X_{i,j}})$表示第i个监控指标监测第j个用户所得数据中大于均值的个数，$K_{i,j}$表示第i个监控指标监测第j个用户采集到的所有数据点的个数。

    d.单位时间折线覆盖面积（编号4）

    \begin{center}
        \begin{figure}[H]
            \begin{center}
                \includegraphics[width=0.50\linewidth]{pic/4.jpg}
            \end{center}
        \end{figure}
        图4：典型折线图4
    \end{center}

    从图中可以看出，虽然该用户有较高的峰值，但整体使用时间及频率较低，故采用折线覆盖面积来评定用户的整体行为。同时，为了避免不同用户的监测时间跨度不同，本文采用单位时间内的折线覆盖面积。

    \[
        \frac{1}{K_{i,j}-1} \times \sum_{k=1}^{K_{i,j}-1}\frac{(X_{i,j,t_{k+1}}+X_{i,j,t_k})\times (t_{k+1}-t_k)}{2}
    \]

    其中，$K_{i,j}$是指第i个监控指标监测第j个用户采集到的所有数据点的个数，$X_{i,j,t_k}$是指监控指标特征i监测第j个用户在第k个时间采集点的数据。

    e.平滑处理最大值（编号5）

    \begin{center}
        \begin{figure}[H]
            \begin{center}
                \includegraphics[width=1.00\linewidth]{pic/5.jpg}
            \end{center}
        \end{figure}
        图5：典型折线图5
    \end{center}

    左图用户监控指标的数值虽然有多个峰值，但相较右图，其最大值维持时间不长，并不稳定。根据经验判断，最大值的稳定性对用户的流失性存在一定的影响。故本文平滑处理了每个点后再取最大值，作为另一个数字特征。
    
    \[
        NewX_{i,j,t_k}=\frac{\sum_{k=k-5}^{k+5}X_{i,j,t_k}}{11}  \qquad  max{NewX_{i,j,t}}
    \]

    其中$NewX_{i,j,t_k}$指的是更新后的监控指标特征i监测第j个用户在第k个时间采集点的数据。

    \subsection{相关性模型建立}

    本文需找出与流失用户特征相关的监控指标。由于附件中的所有用户均是流失用户，故应尽可能寻找这些用户的共同点，即若不同用户间某一监控指标数字特征较为相似，则视为该指标对流失性的贡献较大。

    将每一个监控指标数字特征均归一化处理后，计算其样本方差，其中，均方误差越小的特征越能反映流失性。大致公式如下：

    \[
        X1_{i,j}=\frac{X_{i,j}-min(X_{i,j})}{max(X_{i,j})-min(X_{i,j})}
    \]

    \[
        MseX_i=\frac{\sum_{j=1}^{N_i}(X1_{i,j}-\overline{X1_{i}})^2}{N_i-1}
    \]

    其中，$X_{i,j}$是指监控指标特征i监测第j个用户所获取的数据，其中i为四维数组，前三维为题中给出的监控特征，第四维是数字特征的编号，$X1_{i,j}$是指归一化处理后的数据，$N_i$是指监控指标特征i监测到的用户总数，$\overline{X1_{i}}$是指归一化处理后的数据的均值，$MseX_i$是指该监控指标特征归一化后该组数据的样本方差。



    附件1给出了每个监控指标监测用户当天状态所得到的三种数据，最大值、最小值、平均值，其中最大值和最小值有很多缺失值，且并不能很好地反映用户当天的数据，本文选用平均值进行处理，同时根据上文中我们归纳得出的5种数字特征，针对每个监控指标给出5种细化分类进行相关性分析。

    经计算可得，样本方差的范围约在0.004-0.176间（具体各特征方差见附录<样本方差.processed>），由于归一化后的数据仅能忍受0.1范围内的误差，故取0.01内的样本方差所在的监控指标。统计后发现，绝大部分所选的监控指标4个特征方差都较为相近，把其归为Level1，以此类推，有3个特征方差较为相近的归为Level2,2个记为Level3，1个记为Level4。


    \subsection{结果展示}

    Level1（最重要）: 1,1,2; 1,1,4; 4,1,2; 4,1,3; 4,2,1; 4,2,2; 4,2,3; 4,2,4; 10,1,9; 10,1,12; 10,1,18; 13,1,8; 13,1,11

    Level2（次重要）: 10,1,7; 10,1,11; 13,1,6; 13,1,7; 13,1,9

    Level3（较重要）: 1,1,3; 4,1,1; 4,1,4; 4,1,5; 4,2,5

    Level4（稍重要）: 1,1,1; 6,1,4

    \begin{center}
        \begin{figure}[H]
            \begin{center}
                \includegraphics[width=0.75\linewidth]{pic/监控指标筛选分布图.PNG}
            \end{center}
        \end{figure}
        图6：监控指标筛选分布图
    \end{center}
     
    \section{问题二的模型建立与求解}

    部分重要监控指标监测到的用户数据点较少，分析时有可能存在较大误差，故本文将一年内重要监控指标下不到50个监测点的用户筛除，最终保留199个流失用户及175个正常用户的相关数据。

    \subsection{相关性检验}

    在增加正常用户的监测数据后，我们拥有了两类数据，将流失用户设为0，正常用户设为1。对提取出的重要指标的各个特征与用户的类别进行相关性分析。由于是定类数据与定序数据的检验，故本文采用Lambda系数测量他们之间的关系。

    Lambda相关测量法（格特曼的可预测系数），其基本逻辑是：计算以一个定类变量的值来预测另一个定类变量的值时，如果以众数作为预测标准，可以减少多少误差。消减的误差在全部误差中占比越大，则说明两个变量的相关性越强。

    其往往有两种测量方式：

    1）对称形式：该形式假定两个变量之间的关系是对称的，即不区分自变量和因变量；

    2）不对称形式：该形式要求一个变量为自变量，另一个变量为因变量。

    由于定类变量只有类别而没有高低或者数量的区分，故其相关性没有正负方向，取值范围为[0,1]之间，越接近1则说明相关性越强。

    利用SPSS检验，发现绝大部分监控指标的特征与用户类别的相关性为0.32，说明具有一定的相关性，可以进行进一步的处理。举例如下：

    \begin{center}
        \begin{figure}[H]
            \begin{center}
                \includegraphics[width=0.75\linewidth]{pic/相关性.jpg}
            \end{center}
        \end{figure}
        图7：相关性检验
    \end{center}

    该分析显示该监控指标特征与用户类型在对称形式下的相关性为0.322，且在最后一列显著性水平P值中，可看到P值为0，说明样本中存在的相关性在总体中是显著存在的。

    \subsection{主成分分析法的尝试}

    本小组初始采用主成分分析法来给指标特征进行赋权，发现可以压缩成9个不同变量，解释性在93\%以上，具体如下图：

    \begin{center}
        \begin{figure}[H]
            \begin{center}
                \includegraphics[width=0.75\linewidth]{pic/陡坡.png}
            \end{center}
        \end{figure}
        图8：陡坡图
    \end{center}

    将相关系数除以相应特征根开根号后得到9个新的变量，分别为：

    \begin{center}
        \begin{figure}[H]
            \begin{center}
                \includegraphics[width=0.75\linewidth]{pic/变量系数.jpg}
            \end{center}
        \end{figure}
        图9：变量系数
    \end{center}

    9个变量赋权系数分别为：0.3268,0.2484,0.1445,0.0605,0.0412,0.0399,0.0345,0.0211,0.0187。按照这个赋权方式对用户进行评分，排序后发现预测的正确率仅在60\%到70\%之间，并不能很好地符合要求。

    同样是构造线性损失函数，主成分分析有过大的不确定性，于是本小组决定采用最小二乘法来构建更优解。

    \subsection{最小二乘法模型}

    在问题1的分析中，我们得到了25个重要监控值。同时，对于每个监控值的时序数据，我们得到了4种提取其特征的方法，那么对于附件1和附件3中的每一个用户，我们都可以将它们一年内的时序数据用$25*4=100$个特征值来描述（如果该用户没有某项重要监控值，那么该监控值得到的特征我们将用平均值填补）。

            那么我们就将附件1和3的每个用户的数据转化成了一个100维的向量$X$和一个0/1标记$b$（0表示该用户为流失用户，1表示正常用户）。

            我们将用户的各项特征值加权相加得到的数作为流失风险定量分析指标$f(X)$，该值越小表示用户粘性越小，即流失风险大。
            \[
                f(X)=\Sigma_{i=1}^{100}{a_i X_i}
            \]

            根据附件1、3中提取到的用户数据，设用户数为$n$，用户数据分别为$X^1,\dotsc,X^n$，我们可以列出$n$个方程
            \begin{equation}
                \begin{cases}
                \Sigma_{i=1}^{100}{a_i X^1_i}=b_1\\
                \Sigma_{i=1}^{100}{a_i X^2_i}=b_2\\
                \dotsc\\
                \Sigma_{i=1}^{100}{a_i X^n_i}=b_n
                \end{cases}
            \end{equation}
            设用户数据矩阵为
            \begin{equation}
                D_{100*n}=\begin{pmatrix}
                    X^1\\
                    X^2\\
                    \dotsc\\
                    X^n
                \end{pmatrix}
            \end{equation}
            
            则容易将方程组转化成矩阵形式$Da=b$，那么就可以使用最小二乘法计算最合适的权值$a=(D^TD)^{-1}D^Tb$。(具体计算可运行附件中的代码得到)

            最后我们计算每个用户的流失风险指标，结果如下（横坐标为用户输入顺序，总坐标为用户的流失风险指标）
            \begin{center}
                \begin{figure}[H]
                    \begin{center}
                        \includegraphics[width=0.75\linewidth]{pic/pic1.jpg}
                    \end{center}
                \end{figure}
                图10：用户流失风险指标分布图
            \end{center}

            计算发现，流失用户的风险指标平均数为$0.2219$，明显低于正常用户的平均数$0.6316$；同时我们也可以在上图中发现，表示流失用户的点大多聚集在图的下方，该表现和平均数的表现一致，也和我们的预期一致；故该方法得到的流失风险指标是基本可靠的。

        \subsection{流失风险分级}

        根据计算结果，本文给出如下流失风险分级：

        \begin{center}
            \textbf{表2：流失风险分级表}
            \\ \hspace*{\fill} \\

            \begin{tabular}{|c|c|c|c|c|}
                \hline
                风险等级&数值范围&流失用户数&正常用户数&流失率\\
                \hline
                一级&r<0&23&1&95.8$\%$\\
                \hline
                二级&$0\leq r<0.2$&60&17&77.9$\%$\\
                \hline
                三级&$0.2 \leq r<0.4$&86&38&69.4$\%$\\
                \hline
                四级&$0.4 \leq r<0.6$&21&29&42.0$\%$\\
                \hline
                五级&$0.6 \leq r<1.0$&8&58&12.1$\%$\\
                \hline
                六级&r>1.0&1&36&2.7$\%$\\
                \hline
            \end{tabular}\\
        \end{center}

        表中的流失用户数及正常用户数是根据附件1和附件3中的过往数据得出，从中可以看出风险分级的合理性。从表格中可以看出，随着等级的逐级升高，流失率越来越低，表示该风险级别是正常用户的概率较高。并且，每个风险等级一和六人数分布较少，风险等级三和四人数分布较多，与现实情况较为相符。

        下图给出具象化的分级情况：

        \begin{center}
            \begin{figure}[H]
                \begin{center}
                    \includegraphics[width=0.50\linewidth]{pic/风险分级.PNG}
                \end{center}
            \end{figure}
            图11：流失风险等级可视图
        \end{center}

        \section{问题三的模型建立与求解}
    \subsection{基本假设}
    根据统计建模的基本假设，我们假定用户流失与否与所给的监控数据之间满足某种分布，
    且对用户不同时间点的监控采样是独立同分布的。
    \subsection{模型建立}
    本题欲根据已知数据集的监测指标情况，构建用户流失预测模型；而考虑到流失与否
    是一个二分的状态变量、所给特征指标具体含义未曾得知，故可用统计学习方法中的分类算法学习所给数据集
    建立预测模型。具体地我们使用分类与回归树（CART）算法，对题一中筛选出的重要指标进行划分、建立决策树。
    \subsection{CART算法概述}
    CART假设决策树为二叉树，内部节点的取值均为“是”或“否”，
    分别对应左、右分支。CART算法递归地二分每个特征，将特征空间在有序性度量指标的意义下进行优化分割，
    并在每个分割出的单元确定预测的概率分布。实现过程主要由决策树生成与决策树剪枝两步构成。
        \subsubsection{决策树生成}
        CART生成算法的关键是找到合适的有序性的度量指标，并在其意义下确定该特征的最优二值切分点。
        这里我们采用的是最广为接受的基尼(Gini)指数作为分类指标。
        分类时假设有K个类，样本点属于第k个类的概率为$p_k$，则其定义如下：
            \begin{equation}
               Gini(p)=\sum_{k = 1}^{K}p_k*(1-p_k)  
            \end{equation}
            如果样本集合D根据特征A是否取某一可能值a被分割成$D_1$和$D_2$两部分，即:
            \begin{equation}
             D_1 = \{ (x,y)\in D|A(x)=a\},D_2=D-D_1   
            \end{equation}   
            则在该特征下基尼指数为：
            \begin{equation}
                Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+ \frac{|D_2|}{|D|}Gini(D_2)
            \end{equation}
            基尼指数Gini(D)表示集合D的不确定性，基尼指数Gini(D,A)表示经A=a分割后集合D的不确定性。
            每次根据基尼指数递归选择某个特征的最优切割点，直至达到基尼指数足够小等设定的收敛条件为止，
            再对各个特征逐步进行切割，最终得到决策树。
        \subsubsection{决策树剪枝}
        剪枝根据决策树(T)的损失函数进行：
        \begin{equation}
            C_\alpha (T)=C(T)+ \alpha |T |
        \end{equation}
        其中$C(T)$为对训练数据的预测误差（此处即为基尼指数）；$|T|$为树的叶结点个数，
        代表着树的复杂度，$\alpha$为其权重系数。剪枝时通过递归地使子节点回退到其父节点，
        计算此时损失函数的值，若其相对更小，则剪去子节点。通过随机化搜索权重系数$\alpha $取值，
        获得对应情况最优剪枝后的决策树序列，再进行交叉验证的方式从该序列中选出最佳的树即可。
    \subsection{算法实现}
    基于以上原理，我们在python环境下利用sklearn功能包中的DecisionTreeClassifier这一决策树工具进行了实现。
    实现时以Gini指数为决策指标，通过网格随机搜索、三折交叉验证的方法进行决策树部分超参数的自动调优，在题目所给的F1-score的意义下选取相对更优化的参数最终建立决策树。
    其中对数据集中用户的流失与否进行了编码，流失状态标签记为0，不流失则为1。最终得到一个关于$\{0,1\}$二分类的决策树模型。
    具体实现过程见支撑文件。
    \subsection{模型结果分析}
        \subsubsection{用户流失判别标准分析}
        通过建立的决策树分类节点可以清晰地发现，在被分为流失一类的用户中，其各项综合监控指标均相对趋于0。
        结合所选取的综合指标中有原始监控值的差分绝对值平均数、单位时间曲线覆盖面积等含义，可以得出用户在流失时
        大部分监控值均降至相对历史平均的较低水平，且较稳定地保持在这一水平。流失用户的具体判别标准见下图：\\

        \begin{center}
            \begin{figure}[H]
                \begin{center}
                    \includegraphics[width=0.75\linewidth]{pic/一.jpg}
                \end{center}
            \end{figure}
            图12：流失用户具体判别标准
        \end{center}
        

        由决策路径可知，模型主要根据特征向量的部分分量进行分类；对照特征指标的构造，表现出模型主要依赖部分监测指标的相对大小构建。
        其差分绝对值平均数、单位时间曲线覆盖面积等刻画变化规律的量，对流失用户判断有较强指示作用。
        
        \subsubsection{模型准确性分析}
        利用附件一中的流失用户对模型进行测试，所得结果如下：\\

        \begin{center}
            \begin{figure}[H]
                \begin{center}
                    \includegraphics[width=0.50\linewidth]{pic/二.jpg}
                \end{center}
            \end{figure}
            图13：流失用户测试结果
        \end{center}

        再通过各自选择两种类型用户中监测指标信息较为丰富的用户，混合得到374个测试样本，对其进行测试结果如下：\\

        \begin{center}
            \begin{figure}[H]
                \begin{center}
                    \includegraphics[width=0.50\linewidth]{pic/三.jpg}
                \end{center}
            \end{figure}
            图14：混合样本测试结果
        \end{center}
        
        根据测试数据进一步计算模型的准确率、召回率、F1-score结果如下：
        \begin{equation}
            precision=\frac{TP}{TP+FP}=\frac{130}{130+20}=0.87
        \end{equation}
        \begin{equation}
            recall=\frac{TP}{TP+FN}=\frac{130}{130+45}=0.74
        \end{equation}
        \begin{equation}
            F1=2*\frac{precision*recall}{precision+recall}=0.8
        \end{equation}
        由以上指标可见,本模型对用户流失与否有着较好的预测能力。

\section{问题四的模型建立与求解}
        \subsection{模型建立}
        通过问题三的求解，我们已经大致掌握了利用重要监控指标预测用户流失与否的模型。
        为了得到用户流失时间的估计，同时利用前序结果，此处我们通过转化问题，仍使用三题中训练好的模型
        进行预测。具体地通过对时间进行切片，计算待预测用户不同时间节点处的综合监测指标，
        再分别利用三中模型对此时用户流失情况进行预测；基于用户流失时各指标有相对稳定表现，可以比较各个时间点处
        的流失预测结果、进而得到用户流失情况转折节点，根据转折点时间便可预测用户流失时间的区间。
        \subsection{算法实现}
        \begin{enumerate}
            \item 从用户初次使用时间点开始计时一年，每隔一个月进行切片，计算各段时间内的综合监测指标
            \item 利用训练的决策树模型对用户各段时间的指标进行预测，得到随时间变化的预测结果序列
            \item 考虑到可能的短期“回头客”现象的干扰，取预测序列中最后一次预测为不流失的时间节点，再将其后推一个月作为用户的最终流失节点
            \item 根据上述结果给用户打上不同的流失时间区间标签
        \end{enumerate}


        \section{模型的评价与改进方向}
        \subsection{问题一}
			\subsubsection{优点}
				\begin{itemize}
					\item 筛选出的监控值在大部分用户数据中都有记录，得到的模型适用性强
				\end{itemize}
            \subsubsection{缺点}
                \begin{itemize}
                    \item 提取监控值的特征的方法较为简单，可能无法提取足够多的信息
                    \item 判断特征值有效性时只考虑了附件1中的样本特征，这些样本都为流失用户，其他到的特征可能对分辨是否流失意义不大
            	\end{itemize}
			\subsection{问题二}
				\subsubsection{缺点}
					\begin{itemize}
						\item 使用特征值判断的流失风险的函数过于简单，可能无法表现多特征同时对流失性造成的影响
						\item 只使用了问题一选取出的重要监控值，对于没有这些监控值的用户判断能力较差
					\end{itemize}
        

    \section{附录}
        \subsection{附录1：支撑材料文件列表}
        \begin{center}
            \begin{tabular}{|c|c|}
                \hline
                文件名列表&文件内容\\
                \hline
                附件5.csv&附件4中的用户流失性判断及流失时间预测结果\\
                
                删除数据.xlsx&数据预处理时由于监测用户过少删去的监控指标\\
                指标值统计.txt&监控指标编号及所监测的用户数统计\\
                样本方差数据.processed&第二问判断监控指标重要性的依据\\

                decision\_tree code.py&三四问中决策树实现的相关代码\\

    
                \hline
            \end{tabular}\\
        \end{center}

       
        \subsection{附录2：代码展示}
        \begin{flushleft}
        \begin{lstlisting}[caption={数据预处理代码}]


\end{lstlisting}
\end{flushleft}

\begin{flushleft}
    \begin{lstlisting}[caption={三、四问预测python代码}]
        # %%
import pandas as pd
from sklearn.tree import DecisionTreeClassifier as dtc
import numpy as np
from sklearn.tree import plot_tree
from sklearn.model_selection import RandomizedSearchCV
import seaborn as sns
import matplotlib.pyplot as plt
pd.set_option('display.max_columns',None)

# %%
df=pd.read_csv("C:/Users/Krebs/Desktop/task3_train_data.txt",header=None,sep=' ')

# %%
df_1=pd.read_csv("C:/Users/Krebs/Desktop/data/附件1测试数据",header=None,sep=' ')

# %%
train_x=df.iloc[:,1:101]
train_y=df.iloc[:,101]

# %%
param_grid={
    'min_samples_leaf':np.arange(0.05,0.75,0.05),
    'max_leaf_nodes':range(2,50,1),
    'random_state':range(0,100)
}
rs=RandomizedSearchCV(dtc(),param_grid,n_iter=1000,cv=3,scoring='f1',n_jobs=1)
# %%
rs.fit(X=train_x,y=train_y)
best_para=rs.best_params_

dt=dtc(best_para)

# %%
dt.fit(X=train_x,y=train_y)

# %%
dt.score(X=train_x,y=train_y)

# %%
df[102]=dt.predict(X=train_x)

# %%
df_1[102]=dt.predict(X=df_1.iloc[:,1:101])

# %%
df_1[102].value_counts()

# %%
tp=df[(df[101]==1) & (df[102]==1)].shape[0]
fp=df[(df[101]==0) & (df[102]==1)].shape[0]
pcs=tp/(tp+fp)
pcs

# %%
fn=df[(df[101]==1) & (df[102]==0)].shape[0]
rc=tp/(tp+fn)
fn

# %%
F1=2*pcs*rc/(pcs+rc)
F1

# %%
plt.figure(figsize=(20,20))
plot_tree(dt)
plt.title('Tree')
plt.savefig('tree.jpg')

# %%
plt.figure(figsize=(10,10))
sns.countplot(x=df[102],hue=df[101])
plt.xlabel('predict')
plt.legend(['0','1'])
plt.savefig('2.jpg')

# %%
t=pd.read_csv("C:/Users/Krebs/Desktop/data/data4_1.data",header=None,sep=' ')
ddf=pd.DataFrame(t[0])
ddf

# %%
for i in range(1,13):
    loc='C:/Users/Krebs/Desktop/data/data4_'+str(i)+'.data'
    t=pd.read_csv(loc,header=None,sep=' ')
    p_y=dt.predict(X=t.iloc[:,1:101])
    ddf['mon_'+str(i)]=p_y
ddf

# %%
ddf.describe()

# %%
grade=[]
for i in range(0,200):
    val=ddf.iloc[i,1:13].values
    if 1 not in val:
        grade+='A'
    else:
        for j in range(11,-1,-1):
            if val[j]==1:
                j+=2
                break
        if j<=3:
            grade+='B'
        elif j<=6:
            grade+='C'
        else:
            grade+='D'
ddf['grade']=grade
ddf

# %%
ddf.rename(columns={0:'id'},inplace=True)

# %%
ans=ddf[ddf['mon_12']==0][['id','grade']]
ans.to_csv('附件5.csv')

# %%
plt.figure(figsize=(10,10))
sns.countplot(x=df_1[102])
plt.xlabel('predict')
plt.savefig('3.jpg')



\end{lstlisting}
\end{flushleft}

        
\end{document}


